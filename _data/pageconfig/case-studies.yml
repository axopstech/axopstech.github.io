tagline_intro: Case Studies
tagline_main: "Our Projects: Past & Present"
tagline_here: Case Studies
page_slug: /case-studies
site_url: https://axopstech.github.io
services: 
  - 
    name: Process Automation
    slug: /case-studies/process-automation
    enabled: true
  - 
    name: Cloud Engineering
    slug: /case-studies/cloud-engineering
    enabled: true
  - 
    name: Serverless Computing
    slug: /case-studies/serverless-computing
    enabled: true
  - 
    name: Application Engineering
    slug: /case-studies/application-engineering
    enabled: true
  - 
    name: Blockchain Development
    slug: /case-studies/blockchain-development
    enabled: false

industries:
  - 
    name: Energy
    slug: /case-studies/industry/energy
  - 
    name: FinTech
    slug: /case-studies/industry/fintech
  - 
    name: Construction
    slug: /case-studies/industry/construction
  - 
    name: Financial Services
    slug: /case-studies/industry/financial-services
  - 
    name: Social Media Sites
    slug: /case-studies/industry/social-media-sites

scales:
  - 
    name: Startup
    slug: /case-studies/scale/startup
  - 
    name: Enterprise
    slug: /case-studies/scale/enterprise
  - 
    name: Small & Midsize Business
    slug: /case-studies/scale/small-midsize-business

members:
  solution-architecture-financial-asset-management-quantitative-research-development-firm:
    enabled: true
    title: "Case Study: Financial Asset Management Portal, CRM & ERP on AWS"
    subtitle: Consultative Support for Architecting a Bespoke Financial Asset Management Solution for a Quant R&D Firm.
    slug: solution-architecture-financial-asset-management-quantitative-research-development-firm
    image_src: &site_url /assets/img/illustrations/case-studies/solution-architecture-financial-asset-management-quantitative-research-development-firms.jpg
    industry: "Financial Services"
    service: "Application Engineering"
    scale: "Enterprise"
    challenges: >
      <p>A Quantitative Research & Development firm specializing in financial services approached us for consultative support in designing a robust, scalable solution to manage its growing portfolio of quantitative research products and services. The firm offers sophisticated financial models, data analytics, and investment insights to a wide range of clients, including large financial institutions and individual investors.</p>

      <p>Their existing system was struggling to handle the increasing demand for real-time data processing from multiple market data feeds and alternative data sources, accessible via APIs. Additionally, the firm needed a solution to unify financial portfolio management with a custom-built CRM and ERP system to streamline internal operations and enhance customer relationship management.</p>
    research_and_development: >
      <p>The primary objectives of the client were:
        <ol>
          <li>Integrate real-time market and alternative data sources, enabling the firm to enhance its quantitative research capabilities and provide timely insights to its clients.</li>
          <li>Create a unified system that could manage financial portfolio research and client interactions via a custom-built CRM and ERP system.</li>
          <li>Ensure scalability for future growth as the firm expanded its client base and product offerings.</li>
          <li>Provide robust, multi-tenant support to cater to both institutional and individual clients while maintaining data security and segregation.</li>
        </ol>
      </p>

      <p>We began by analyzing the firm’s current infrastructure, which was fragmented and not capable of handling the firm’s expanding needs. Their legacy systems struggled with integrating third-party data feeds and supporting real-time analytics for portfolio management. Additionally, the current CRM and ERP systems were largely off-the-shelf solutions that lacked customization, creating inefficiencies in managing customer relationships and internal operations.</p>

      <p>Key findings included:
        <ol>
            <li><b>System Fragmentation:</b> The firm’s tools for quantitative research, CRM, and ERP were isolated from each other, resulting in significant data silos and process inefficiencies..</li>
            <li><b>Lack of Scalability:</b> The current systems could not handle the growing volume of data or the increasing complexity of the firm’s research products.</li>
            <li><b>Security Gaps:</b> The system needed to be more secure, particularly with respect to handling sensitive financial data and managing multiple clients under a multi-tenant architecture.</li>
        </ol>
      </p>

      <p>Based on this analysis, we recommended leveraging AWS cloud-native services for their ability to integrate seamlessly with third-party APIs, provide scalability, and maintain high levels of security.</p>

      <p>Key services recommended:
        <ol>
            <li><b>Amazon RDS</b> for managing relational data, allowing for structured storage of client portfolios, CRM records, and ERP transactions.</li>
            <li><b>AWS Lambda</b> for serverless, real-time data processing, enabling the firm to process large amounts of data from multiple sources without the need for dedicated infrastructure.</li>
            <li><b>Amazon API Gateway</b> to manage external data integrations, particularly market data feeds and alternative data sources that the firm relies on for quantitative analysis.</li>
            <li><b>Amazon S3</b> for secure and scalable storage of large datasets and research outputs.</li>
            <li><b>AWS Cognito</b> to manage multi-tenant user authentication and ensure secure client access while adhering to strict data privacy requirements.</li>
        </ol>
      </p> 

    architecture: >
      <p>The architecture we recommended was designed with flexibility, scalability, and security in mind, with a focus on unifying the firm’s operations and allowing it to expand its product offerings with minimal disruption.
        <ol>
            <li><b>Data Storage:</b> We proposed Amazon RDS to store structured data related to the firm’s research products, client portfolios, CRM, and ERP activities. This would enable the firm to store, query, and manage large datasets with ease, while also supporting future scalability needs.</li>
            <li><b>API Integration:</b> To integrate market and alternative data feeds, Amazon API Gateway was recommended. This would act as a central interface for pulling in real-time data from external sources and feeding it into the firm’s quantitative models. The gateway would provide secure and scalable access to these APIs, ensuring that data could be processed efficiently, regardless of volume.</li>
            <li><b>Business Logic and Data Processing:</b> AWS Lambda was recommended to handle serverless execution of the firm’s data processing algorithms, including real-time analytics, portfolio management updates, and other critical computations. This would allow the firm to handle large amounts of data without the need for traditional servers, reducing infrastructure costs and improving system responsiveness.</li>
            <li><b>Multi-Tenant Support:</b> AWS Cognito was recommended to manage user authentication and ensure secure, segregated access to the platform. Each client (institutional or individual) would have their own data partition in RDS, allowing them to interact with their portfolio and research tools securely, while IAM policies would restrict access to sensitive internal operations.</li>
            <li><b>Security and Compliance:</b> The firm required a solution that adhered to strict security and compliance guidelines, especially given its dealings with financial institutions. Encryption at rest and in transit was to be implemented via AWS Key Management Service (KMS). We also recommended using AWS CloudTrail and AWS Config to provide real-time monitoring, auditing, and compliance reporting.</li>
        </ol>
      </p>

    deployment: >
      <p>Though the solution was still in the design phase, we provided clear recommendations for how to deploy it effectively:
        <ol>
          <li><b>Infrastructure as Code:</b> We advised using AWS CloudFormation to define and automate the infrastructure setup. This would ensure consistent deployments across different environments (development, staging, and production) and allow the firm to quickly provision resources as their needs grew.</li>
          <li><b>CI/CD Pipeline:</b> To support continuous integration and deployment, we recommended the implementation of AWS CodePipeline and CodeDeploy. This would allow for fast, reliable updates to the platform without downtime, ensuring that new features and bug fixes could be rolled out in a controlled manner.</li>
          <li><b>Security Best Practices:</b> To secure the infrastructure, we recommended configuring security groups, VPCs, and NACLs to control network access, ensuring that only trusted sources could communicate with critical resources. Additionally, we proposed regular penetration testing and security audits to identify and address potential vulnerabilities.</li>
          <li><b>Testing & Validation:</b> We recommended a thorough testing strategy that included performance tests to validate the scalability of real-time data processing, security tests to ensure that sensitive client data remained secure, and user acceptance tests to ensure that the CRM and ERP systems met the firm’s operational needs.</li>
        </ol>
      </p>

    conclusion: >
      <p>Our consultative support provided the Quantitative Research & Development firm with a clear roadmap for modernizing its technology infrastructure. By proposing a cloud-native solution built on AWS, we addressed key operational challenges, including system fragmentation, scalability limitations, and security gaps.</p>

      <p>The recommendations positioned the firm to:
        <ol>
          <li><b>Unify Operations:</b> By integrating portfolio management, CRM, and ERP functions into a single platform, the firm would be able to operate more efficiently and provide a higher level of service to its clients.</li>
          <li><b>Scale Effectively:</b> The proposed architecture would allow the firm to handle increasing data volumes and client demands without sacrificing performance.</li>
          <li><b>Enhance Research Capabilities:</b> Real-time data integrations would allow the firm to deliver timely insights to its clients, strengthening its position as a leading provider of quantitative research.</li>
          <li><b>Improve Security:</b> By adhering to AWS’s Well-Architected and Security Reference frameworks, the firm would ensure compliance with financial regulations while protecting sensitive client data.</li>
        </ol>
      </p>
      
      <p>These recommendations provided the firm with a comprehensive, secure, and scalable foundation for future growth.</p>
      
    technologies:
      - S3
      - SQL
      - Lambda
      - Textract
      - Step Functions
    
  automating-manual-data-entry-serverless-aws-on-prem-proprietary-apis.md:
    enabled: true
    title: "Case Study: Automating Data Entry in On-Prem CRM with AWS Services"
    subtitle: Consultative and Engineering Support towards automating legacy data entry processes in an on-premise CRM.
    slug: automating-manual-data-entry-serverless-aws-on-prem-proprietary-apis
    image_src: &site_url /assets/img/illustrations/case-studies/automating-manual-data-entry-serverless-aws-on-prem-proprietary-apis.jpg
    industry: "Financial Services"
    service: "Process Automation"
    scale: "Small & Midsize Business"
    challenges: >
      <p>The client, a mid-sized firm in the financial services sector, was struggling with manual data entry processes involving scanned documents, such as quarterly accounts submissions, contracts, and compliance forms. These documents needed to be processed into an on-prem CRM, where key data points could be extracted and stored for further processing, analysis, and decision-making.</p>

      <p>Previously, the client relied on a combination of manual entry and rudimentary OCR (Optical Character Recognition) tools to extract data from scanned documents. The manual process led to several operational inefficiencies, including delays in processing time, human errors, and significant overhead costs. Additionally, the existing OCR tools had limited accuracy and did not integrate well with their legacy on-premise CRM, leading to further workflow disruptions.</p>

    research_and_development: >
      <p>The primary objectives of the client were:
        <ol>
          <li>Automating data extraction from scanned documents and importing it into their CRM.</li>
          <li>Reducing human error and accelerating the data processing times.</li>
          <li>Ensuring scalability to handle increasing document volumes.</li>
          <li>Providing a cost-effective solution that could scale without the need for significant infrastructure investments or specialised personnel on staff.</li>
        </ol>
      </p>

      <p>During the research phase, we conducted an in-depth analysis of the client’s existing data entry workflow. Key bottlenecks were identified, including slow OCR performance, limited CRM integration, and the need for significant manual intervention. The client also expressed concerns about the scalability of their current process as the volume of incoming documents increased.</p>

      <p>To address these challenges, we proposed leveraging AWS’s serverless offerings for scalable and more accurate OCR processing. After evaluating various options, we proposed the following:
        <ol>
            <li><b>Amazon Textract</b> for OCR processing due to its ability to automatically extract text, forms, and tables from scanned documents with high accuracy.</li>
            <li><b>AWS Lambda</b> for serverless execution of OCR tasks, and a pay-per-use model without managing servers.</li>
            <li><b>Amazon S3</b> for storage of the scanned documents before and after OCR processing.</li>
            <li><b>AWS Step Functions</b> to orchestrate the OCR workflow.</li>
            <li><b>Proprietary APIs</b> to integrate with AWS and automatically push processed data into the client's on-premise CRM.</li>
        </ol>
      </p>
      <p>These services were selected for their seamless integration with each other in AWS Cloud, and their pay-as-you-go pricing model, which ensured the client only paid for the resources they used.</p>

    architecture: >
      <p>The solution was designed to be entirely serverless, ensuring that it could scale effortlessly with the client’s growing document processing needs. The architecture included the following key components:
        <ol>
            <li><b>Amazon S3:</b> Scanned documents are uploaded to an S3 bucket, triggering the processing workflow.</li>
            <li><b>AWS Lambda:</b> A Lambda function is triggered by the upload of a new document to S3. This function calls Amazon Textract to perform OCR on the document.</li>
            <li><b>Amazon Textract:</b> Textract processes the document and extracts the required data points, including both structured and unstructured data such as names, addresses, and financial amounts.</li>
            <li><b>AWS Step Functions:</b> Step Functions coordinate the workflow, handling failures, retries, and orchestrating the process of calling Textract, validating the results, and pushing the data to the client's CRM via a proprietary REST API.</li>
            <li><b>Proprietary APIs</b>: The extracted data is sent via REST API calls to an on-prem Windows Server, where it is mapped to the appropriate fields in the client’s CRM system.</li>
        </ol>
      </p>

      <p>This architecture provided several benefits:
        <ol>
          <li><b>Scalability</b>: The serverless design allowed the client to process a large number of documents simultaneously without any performance degradation.</li>
          <li><b>Cost Efficiency</b>: Since the chosen AWS services are pay-per-use, the client only incurred costs when documents were processed, eliminating the need for upfront infrastructure investment.</li>
          <li><b>Automation</b>: The end-to-end automation reduced manual interventions, eliminated errors, and significantly shortened processing times.</li>
          <li><b>Security</b>: Using AWS IAM roles, encryption, and controlled access to S3 buckets, the data of the client and its customers remained segregated, secure and compliant with industry standards.</li>
        </ol>
      </p>

    deployment: >
      <p>The deployment was divided into several key stages, ensuring a smooth rollout:
        <ol>
          <li><b>Infrastructure Setup:</b>
            <ul>
              <li>S3 buckets were configured to store incoming scanned documents and processed outputs. Permissions were set using AWS IAM to ensure secure access.</li>
              <li>The client’s proprietary API was configured to accept incoming data from AWS Lambda with appropriate OAuth authentication.</li>
            </ul>
          </li>

          <li><b>Lambda Functions and Step Functions:</b>
            <ul>
              <li>AWS Lambda functions were written to trigger OCR processing when a new document was uploaded to S3. Additional functions handled error checking, validation, and communication with the client's on-prem CRM.</li>
              <li>AWS Step Functions were used to orchestrate the entire workflow, ensuring proper sequencing and error handling.</li>
            </ul>
          </li>

          <li><b>On-Prem CRM Integration:</b>
            <ul>
              <li>A custom API integration was developed to map the extracted OCR data to CRM objects.</li>
              <li>Data validation scripts ensured that only accurate and relevant data was pushed into the CRM, avoiding data quality issues.</li>
            </ul>
          </li>
              
          <li><b>Testing and Validation:</b>
            <ul>
              <li>Extensive testing was conducted using a wide variety of scanned documents to ensure that Textract handled various document types (forms, tables, unstructured documents) effectively.</li>
              <li>The solution was tested for performance and scalability by processing large batches of documents simultaneously.</li>
            </ul>
          </li>

          <li><b>CI/CD Pipeline:</b>
            <ul>
              <li>A CI/CD pipeline was established using GitHub Actions to automate deployment and ensure ongoing updates could be rolled out with minimal disruption.</li>
            </ul>
          </li>
        </ol>
      </p>

    conclusion: >
      <p>The implementation of the serverless OCR data processing solution provided significant business value to the client. By integrating AWS's serverless services with the client's on-prem CRM, the client was able to automate a previously manual and error-prone process, resulting in:

        <ol>
          <li><b>80% reduction in processing time:</b> Documents that previously took hours to process manually were now processed in minutes.</li>
          <li><b>Significant cost savings:</b> The client experienced a 35% reduction in operational costs, primarily due to the elimination of manual data entry and the pay-per-use nature of the application.</li>
          <li><b>Improved data accuracy:</b> The solution reduced human errors by automating the data extraction and entry process.</li>
          <li><b>Scalability:</b> The client’s document processing capability scaled effortlessly to meet growing demands without requiring additional infrastructure.</li>
        </ol>
      </p>
      
      <p>The new architecture resolved the client’s pain points by delivering a solution that not only optimized their current workflow but also positioned them for future growth. The use of serverless technology allowed the client to focus on their core business, confident that their data processing system could grow with them.</p>
      
    technologies:
      - S3
      - SQL
      - Lambda
      - Textract
      - Step Functions

  quantum-engineering-at-scale-aws.md:
    enabled: true
    title: "Case Study: Quantum Financial Engineering on AWS Cloud"
    subtitle: Design, development and delivery of a Quantum Platform on AWS Cloud for optimising investment portfolios.
    slug: quantum-engineering-at-scale-aws
    image_src: &site_url /assets/img/illustrations/case-studies/quantum-engineering-at-scale-aws.jpg
    industry: "Financial Services"
    service: "Cloud Engineering"
    scale: "Enterprise"
    challenges: >
      <p>The financial industry has been facing challenges with traditional portfolio optimization methods, 
      which are based on historical data and do not take into account the potential impact of real-time macroeconomic 
      events on investment performance.</p>
      <p>Upon finalising the scope with the client, we set out to create a quantum computing platform on AWS that would 
      address these issues by incorporating quantum computing techniques to optimise investment portfolios under different metrics 
      and by including relevant real-time macroeconomic data.</p>
    research_and_development: >
      <p>Leveraging our experience in Quantitative Finance and Quantum Computing, our research and development personnel began 
      by studying the existing portfolio optimization methods and identifying their limitations in terms of incorporating 
      real-time macroeconomic data and leveraging quantum computing techniques.</p>
      <p>We also conducted market research to understand the specific needs and requirements of financial institutions in terms 
      of portfolio optimization and risk management, together with infrastructure limitations.</p>
      <p>Based on this research, we designed a platform that utilises quantum computing techniques to optimise 
      investment portfolios under different metrics, such as return-to-volatility. The platform also includes a feature 
      that allows for the analysis of a larger universe of assets, including alternative assets and the incorporation of 
      relevant real-time macroeconomic data.</p>
    architecture: >
      <p>To ensure high scalability and performance, we deployed the platform on AWS using a complex and highly available 
      architecture.</p>
      <p>We also improved traditional cybersecurity practices by enabling quantum-encryption of the information 
      with the latest on-cloud security technologies.</p>
    deployment: >
      <p>Once development was complete, we deployed the platform on AWS. The platform was deployed using a Kubernetes cluster, 
      which allowed us to easily scale the solution as needed and handle high traffic loads. </p>
      <p>We used Terraform for infrastructure as code, which allowed us to easily provision and manage the infrastructure on AWS.</p>
      <p>To store and process the financial data, we used Amazon S3, Amazon DynamoDB, and Amazon Elastic MapReduce (EMR). 
      These services allowed us to store and process the data in a highly available and scalable manner, while also providing 
      built-in security features to protect user data.</p>
    conclusion: >
      <p>Through the development and deployment of this quantum platform on AWS, we were able to provide financial 
      institutions with a more efficient and effective way to optimise investment portfolios.</p>
      <p>The platform incorporates quantum computing techniques and relevant real-time macroeconomic data, allowing for more 
      accurate and robust portfolio optimization.</p>
      <p>By leveraging AWS managed services, we were able to achieve high 
      scalability, performance, and security while complying with industry regulations.</p>
    technologies:
      - S3
      - EC2
      - EKS
      - EMR
      - QLDB
      - DynamoDB
      - Terraform
  
  streamlining-expense-processing-aws-salesforce.md:
    enabled: true
    title: "Case Study: OCR Data Processing in Salesforce with Serverless AWS"
    subtitle: Streamlining Invoice, Receipt, and Timesheet Processing with AWS Lambda, S3, and Salesforce Apex Batch Jobs.
    slug: streamlining-expense-processing-aws-salesforce
    image_src: &site_url /assets/img/illustrations/case-studies/streamlining-expense-processing-aws-salesforce.jpg
    industry: "Energy"
    service: "Serverless Computing"
    scale: "Enterprise"
    challenges: >
      <p>The client using Salesforce as its CRM, faced challenges with manual processing and review of invoice, timesheet, and receipt data sent in by employees. 
      The process was time-consuming, and certain characteristics of an App the client used to process expenses in their Salesforce instance 
      were insufficient to adequately store the PDF and image files being received.</p>
      <p>To overcome these challenges, a solution was developed to offload the processing to AWS, utilising Amazon S3, AWS Lambda, and Salesforce Apex and SOQL.</p>
    research_and_development: >
      <p>We conducted a thorough analysis of the existing system and its pain points, and identified Amazon S3 and AWS Lambda as the most 
      suitable services to address the client's requirements.</p>
      <p>These services would facilitate the creation of a middleware solution that would enable the client to automate and streamline 
      the process of receiving, uploading, processing, and transferring data between Salesforce and AWS, effectively bypassing the 
      aforementioned limitations by taking advantage of the chosen AWS cloud services.</p>
    architecture: >
      <p>The proposed solution consisted of the following components:</p>
      <p>
        <ul>
          <li>
            <p><strong>Amazon S3</strong>: Employees would upload their invoice, timesheet, and receipt files to a designated S3 bucket prefix. Amazon S3 
            was chosen for its low cost, high availability, and security features. This eliminated the storage-specific limitations faced by the client with 
            their Salesforce App.</p>
          </li>
          <li>
            <p><strong>AWS Lambda</strong>: A serverless AWS Lambda function would be triggered via S3 event notifications whenever a new file was uploaded by an employee. 
            This function would process the files, extracting the relevant data from the data uploaded by the employee using Optical Character Recognition (OCR).
            This not only automated the data extraction process, but would also save the client a tremendous amount of time and effort when compared to manually
            processing uploads as was the case before.</p>
          </li>
          <li>
            <p><strong>Custom Salesforce Integration</strong>: The extracted data would be sent to Salesforce through a custom integration. 
            A Batch Job written in Apex and deployed in Salesforce would periodically call out to the AWS Lambda function, parse the returned data, 
            and ensure that it was stored in the appropriate Salesforce objects as specified by the client. This approach would allow the client to maintain 
            control over the data flow without reinforcing its dependency on the Salesforce App.</p>
          </li>
        </ul>
      </p>
    deployment: >
      <p>The solution was deployed in the following steps:</p>
      <p>
        <ul>
          <li>
            <p>We set up the Amazon S3 bucket with the necessary security and access permissions for employees to upload their files.</p>
          </li>
          <li>
            <p>We then proceeded to develop the AWS Lambda function for processing the uploaded files, leveraging OCR technology to extract relevant data from the 
              uploaded files, and prepare it for outbound transfer to Salesforce.</p>
          </li>
          <li>
            <p>We created a custom Salesforce integration whereby a Salesforce Batch Job written in Apex can call the AWS Lambda function and retrieve the 
            extracted data for subsequent import to Salesforce, mapping the data fields to the appropriate Salesforce objects.</p>
          </li>
          <li>
            <p>Finally, we thoroughly tested the end-to-end integration, ensuring accurate data processing and transfer between AWS and Salesforce.</p>
          </li>
        </ul>
      </p>
    conclusion: >
      <p>By implementing the proposed solution using Salesforce Apex, Amazon S3 and AWS Lambda, the client successfully offloaded the processing of 
      invoice, timesheet, and receipt data to AWS, bypassing certain limitations of their Salesforce App that previously forced the client to 
      manually process uploaded data.</p>
      <p>Our solution streamlined their workflow dramatically, saving time and effort on manual data review and entry, and boosted productivity for 
      both their employees and HR staff.</p>
      <p>The solution also ensured seamless data exchange between Salesforce and AWS through a custom integration, making the process 
      considerably more efficient and accurate, without reinforcing the client's existing licensed software dependencies.</p>
    technologies:
      - S3
      - SSM
      - Apex
      - SOQL
      - Lambda
      - CloudFormation
      
  social-media-super-app-aws.md:
    enabled: false
    title: "Case Study: Social Media Super App Deployment on AWS"
    subtitle: Design, development and delivery of a novel, highly available Social Media App on AWS for fast, global content consumption.
    slug: social-media-super-app-aws
    image_src: &site_url /assets/img/illustrations/case-studies/social-media-super-app-aws.jpg
    industry: "Social Media Sites"
    service: "Cloud Engineering"
    scale: "Startup"
    challenges: >
      <p>The social media landscape is highly competitive, with a variety of platforms catering to different types of content 
      creation and sharing.</p>
      <p>The client envisioned creating a social media super app that would allow users to create and share multiple types of content, 
      such as video, audio, text, audio journaling, and live rooms, all within the same app and user experience.</p>
    research_and_development: >
      <p>Our research and development personnel began by studying the existing social media platforms and identifying their limitations 
      in terms of content creation and sharing. We also conducted market research to understand the specific needs and requirements 
      of users in the social media space.</p>
      <p>Based on this research, we designed a social media super app that allows users to create and share a variety of content 
      types, such as videos, photos, and live streams. The application also includes a feature for audio journaling, which allows users to 
      record and share their thoughts and experiences in an audio format.</p>
    architecture: >
      <p>To ensure scalability and performance, we used a variety of technologies and architectures, including Serverless and Flutter, 
      to cut development times by 2x. </p>
      <p>Specifically, we used AWS Lambda, Amazon S3, and Amazon DynamoDB to achieve 
      high scalability and performance.</p>
    deployment: >
      <p>Once development was complete, we deployed the application on AWS using a microservices 
      architecture, with each service running on a separate AWS Lambda function. This allowed us to easily scale the app as needed 
      and handle high traffic loads on-demand.</p>
      <p>To store the user data, we used Amazon S3 and Amazon DynamoDB, making sure redundancy was taken into account and accordingly 
      deployed. These services allowed us to store the data in a highly available and scalable manner.</p>
      <p>Additionally, we implemented 
      a variety of security best practices, such as encryption in-transit and at-rest, and multi-factor authentication, to ensure 
      the safety and security of user data.</p>
    conclusion: >
      <p>Through the development and deployment of this social media super app on AWS, we were able to provide users with a unique 
      and comprehensive social media experience. The app allows users to create and share a variety of content types, all within 
      the same app and user experience. </p>
      <p>By using Serverless and Flutter on AWS, we were able to achieve 
      high scalability and performance, while also ensuring the security of user data. The app has had zero downtime since its launch and 
      is highly performant, taking into account the fact that it is using resource-heavy user experience components such as 3D environments.</p>
    technologies:
      - S3
      - Lambda
      - Flutter
      - DynamoDB

  multi-tenancy-saas-financial-risk-management.md:
    enabled: true
    title: "Case Study: Multi-Tenancy SaaS for Financial Risk Management"
    subtitle: Modernising traditional risk management operations and improving performance using applied Machine Learning / AI.
    slug: multi-tenancy-saas-financial-risk-management
    image_src: &site_url /assets/img/illustrations/case-studies/multi-tenancy-saas-financial-risk-management.jpg
    industry: "FinTech"
    service: "Application Engineering"
    scale: "Enterprise"
    challenges: >
      <p>In the investment finance industry, risk management and regulatory compliance are a crucial aspect of operations. In this 
      project, we built a multi-tenant SaaS platform that utilises artificial intelligence to automate and analyze risk. </p>
      <p>The platform was deployed on DigitalOcean, using Kubernetes and Terraform to manage the infrastructure.</p>
    research_and_development: >
      <p>The platform's architecture is based on a microservices approach, where each service is responsible for a specific functionality. 
      This allows for greater scalability and flexibility in managing the resources required for each tenant.</p>
      <p>To handle real-time data access, we used the Go programming language, known for its high performance and efficient memory management. 
      Asynchronous programming was used to handle high-performance request processing.</p>
    architecture: >
      <p>For multi-tenancy, we used a multi-tenant architecture that allows for efficient management of resources, including memory, 
      CPU and storage. This also helps in cutting down deployment and server costs.</p>
      <p>For the AI pipeline, we used a combination of machine learning and deep learning techniques to analyze data and identify 
      potential investment risks. This pipeline was integrated with the platform, allowing tenants to access the AI functionality as part of 
      their subscription.</p>
    deployment: >
      <p>To deploy the platform, we used Terraform to provision the infrastructure on DigitalOcean. Kubernetes was used to manage the 
      containerised microservices, allowing for easy scaling and deployment of updates.</p>
      <p>To tackle the complex regulations and data access requirements in the investment finance industry, we conducted extensive 
      research to understand the specific requirements and tailor the technology accordingly.</p>
    conclusion: >
      <p>In summary, the Multi-Tenancy SaaS platform uses AI to automate and analyze risk, is deployed on DigitalOcean, and managed via 
      Kubernetes and Terraform. The platform's architecture is based on microservices, which allows for scalability and flexibility.</p>
      <p>The platform is built with Golang to leverage asynchronous programming, and multi-tenant architecture to handle real-time data 
      access and high-performance request processing. A full AI production pipeline was also deployed as the core of the platform. </p>
      <p>The platform was successfully deployed in a highly regulated environment with complex data access and migration requirements.</p>
    technologies:
      - Golang
      - Terraform
      - Kubernetes
      - DigitalOcean

  blockchain-powered-mobility-service-aws-gcp.md:
    enabled: false
    title: "Case Study: Blockchain-powered Mobility Service on AWS and GCP"
    subtitle: Developing and Deploying a High-Availability Blockchain-based Mobility Solution on AWS and GCP.
    slug: blockchain-powered-mobility-service-aws-gcp
    image_src: &site_url /assets/img/illustrations/case-studies/blockchain-powered-mobility-service-aws-gcp.jpg
    industry: "Transportation"
    service: "Blockchain Development"
    scale: "Startup"
    challenges: >
      <p>The taxi industry has been facing challenges with centralised systems and lack of transparency. Upon finalising the scope with
      the client, we set out to create a highly available, blockchain-based mobility solution for the taxi industry 
      that would address these issues and provide a more efficient and secure service for both customers and drivers.</p>
      <p>By leveraging the strengths of both Amazon Web Services (AWS) and the Google Cloud Platform (GCP), we aimed to create 
      a solution that is scalable, secure, and highly available.</p>
    research_and_development: >
      <p>Our research and development personnel began by studying the existing taxi industry systems and identifying their limitations in 
      terms of transparency and scalability. We also conducted market research to understand the specific needs and requirements of 
      customers and drivers in the taxi industry.</p>
      <p>Based on this research, we designed a blockchain-based mobility solution that utilises smart contracts on the blockchain to 
      ensure transparency and security of all transactions. The solution included a real-time tracking feature, which allows customers 
      to track the location of their taxi in real-time, and a decentralised finance and tokenization feature, which allows customers 
      to pay for their rides using a digital token.</p>
    architecture: >
      <p>To ensure high scalability and performance, we deployed the solution with a multi-cloud architecture on AWS and GCP, using 
      Kubernetes and Terraform. We also used novel technologies to handle real-time tracking and reduce response times by 2x.</p>
      <p>Additionally, we incorporated security measures such as encryption (both in-transit and at-rest), and multi-factor authentication 
      to safeguard user data. To improve the user experience, we used Swift and Kotlin for the front-end and Rust for the back-end, 
      which allowed us to create a fast and responsive application.</p>
    deployment: >
      <p>Once development was complete, we deployed the solution on AWS and GCP. The solution was deployed using a Kubernetes 
      cluster, which allowed us to easily scale the solution as needed and handle high traffic loads.</p>
      <p>We used Terraform for infrastructure-as-code, which allowed us to easily provision and manage the infrastructure on both 
      AWS and GCP simultaneously.</p>
      <p>To store the user data, we used Amazon S3 and Google Cloud Storage. These services allowed us to store the data in a highly 
      available and scalable manner, while also providing built-in security features to protect user data. Additionally, we implemented 
      a variety of security best practices, such as encryption and multi-factor authentication, to ensure the safety of user data.</p>
    conclusion: >
      <p>Through the development and deployment of this blockchain-based mobility solution on AWS and Google Cloud, 
      we were able to provide customers and taxi drivers with a more efficient and secure service. </p>
      <p>The solution addresses the challenges of transparency and scalability that the taxi industry has been facing 
      and modernises the business model with the use of decentralised finance and tokenization.</p>
      <p>By using a multi-cloud architecture on AWS and GCP, and Kubernetes, Terraform, Serverless, and Blockchain, we were 
      able to achieve a highly scalable, performant, and secure solution while safeguarding user data. The use of modern programming languages 
      such as Rust, Swift, and Kotlin helped us to reduce response times by 3x and improve the user experience.</p>
    technologies:
      - Rust
      - Swift
      - Kotlin
      - Terraform
      - Kubernetes
  
  decentralized-p2p-challenges-aws.md:
    enabled: false
    title: "Case Study: Decentralised P2P Collateral Exchange on AWS"
    subtitle: Developing and Deploying a Blockchain-based Social Decentralised Peer-to-Peer Collateral Exchange Platform.
    slug: decentralized-p2p-challenges-aws
    image_src: &site_url /assets/img/illustrations/case-studies/decentralized-p2p-challenges-aws.jpg
    industry: "FinTech"
    service: "Blockchain Development"
    scale: "Startup"
    challenges: >
      <p>The FinTech payments industry has traditionally been centralised, with a few large companies controlling the majority of the market. 
      However, with the advent of blockchain technology, the client saw an opportunity to create decentralised peer-to-peer 
      platforms that are more transparent and secure. </p>
      <p>Upon finalising the scope with the client, we set out to develop such a platform, with a focus on incorporating social 
      features and a proprietary decentralised dispute resolution flow.</p>
    research_and_development: >
      <p>Our research and development personnel began by studying the existing decentralised platforms and identifying their limitations. 
      We also conducted market research to understand the specific needs and requirements of users in the industry.</p>
      <p>Based on this research, we designed a blockchain-based platform that allows users to exchange collateral directly with each 
      other, without the need for a centralised intermediary. The platform utilises smart contracts on the blockchain to ensure the 
      transparency and security of all transactions.</p>
      <p>In addition to this core functionality, we also incorporated several social features, such as live streaming and the ability for 
      users to generate video content. This allows users to interact with each other and share their experiences on the platform.</p>
    architecture: >
      <p>To accomplish the above, we developed the whole architecture on AWS and Kubernetes to ensure high-availability, scalability and 
      security, without any dependency on third-party providers.</p>
      <p>Platforms of this nature often encounter high traffic load on certain events and scenarios. Our case was no different and the social features 
      made it even more sensitive as the whole infrastructure would need to adapt accordingly to the demand, while at the same time being resource-efficient.</p>
      <p>To address this, we ensured that the architecture was built in a highly available, instantly scalable, and fault-tolerant manner.</p>
      <p>To address the issue of dispute resolution, we developed a proprietary decentralised dispute resolution flow. This allows users to 
      resolve disputes in a transparent and fair manner, without the need for a centralised intermediary.</p>
    deployment: >
      <p>Once development was complete, we began the deployment process. This included setting up the necessary infrastructure, such as nodes 
      for the blockchain network and servers for the live streaming functionality on AWS.</p>
      <p>To further enhance the deployment, Kubernetes was used to manage the containerised microservices, allowing for easy scaling and deployment 
      of updates.</p>
    conclusion: >
      <p>Through the development and deployment of this blockchain-based social decentralised peer-to-peer platform, we were able to 
      provide users with a more transparent and secure way to exchange collateral.</p>
      <p>The incorporation of social features and a proprietary decentralised dispute resolution flow sets the platform apart from existing 
      decentralised platforms and creates a unique user experience. The platform has been well received by users and has shown strong 
      growth since its launch.</p>
    technologies:
      - Rust
      - Swift
      - Terraform
      - Kubernetes
      - Smart Contracts
